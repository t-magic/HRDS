{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests == Awesome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests should be the hammer of your data science tool kit. \n",
    "\n",
    "What are they?\n",
    "* Machine learning algorithm built for prediction tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros\n",
    "* Automatically model non-linear relations and interactions between variables. Perfect collinearity doesn't matter.\n",
    "* Easy to tune\n",
    "* Relatively easy to understand everything about them\n",
    "* Flexible enough to handle regression and classification tasks\n",
    "* Is useful as a step in exploratory data analysis\n",
    "* Can handle high dimensional data\n",
    "* Have a built in method of checking to see model accuracy\n",
    "* In general, beats most models at most prediction tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cons\n",
    "* ?\n",
    "* ?\n",
    "* ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple example: Boston Housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Boston Housing dataset\n",
    "from sklearn.datasets import load_boston\n",
    "X, y = load_boston().data, load_boston().target\n",
    "\n",
    "# Make train and test datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print (\"R^2:\", model.score(X_test, y_test).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "print (\"R^2:\", model.score(X_test, y_test).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "print (\"R^2:\", model.score(X_test, y_test).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* Decision trees\n",
    "* Bootstrap sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Random Forest Algorithm\n",
    "\n",
    "The big idea: Combine a bunch of terrible decision trees into one awesome model. \n",
    "\n",
    "For each tree in the forest:\n",
    "1. Take a bootstrap sample of the data\n",
    "2. Randomly select some variables.\n",
    "3. For each variable selected, find the split point which minimizes MSE (or Gini Impurity or Information Gain if classification).\n",
    "4. Split the data using the variable with the lowest MSE (or other stat).\n",
    "5. Repeat step 2 through 4 (randomly selecting new sets of variables at each split) until some stopping condition is satisfied or all the data is exhausted.\n",
    "\n",
    "Repeat this process to build several trees. \n",
    "\n",
    "To make a prediction, run an observation down several trees and average the predicted values from all the trees (for regression) or find the most popular class predicted (if classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Most important parameters (and what they mean)\n",
    " * ###Parameters that will make your model better\n",
    "  * <b>n_estimators</b>: The number of trees in the forest. Choose as high of a number as your computer can handle.\n",
    "  * <b>max_features</b>: The number of features to consider when looking for the best split. Try [\"auto\", \"None\", \"sqrt\", \"log2\", 0.9, and 0.2]\n",
    "  * <b>min_samples_leaf</b>: The minimum number of samples in newly created leaves.Try [1, 2, 3]. If 3 is the best, try higher numbers.\n",
    " * ###Parameters that will make it easier to train your model\n",
    "  * <b>n_jobs</b>: Determines if multiple processors should be used to train and test the model. Always set this to -1 and %%timeit vs. if it is set to 1. It should be much faster (especially when many trees are trained).\n",
    "  * <b>random_state</b>: Set this to 42 if you want to be cool AND want others to be able to replicate your results.\n",
    "  * <b>oob_score</b>: THE BEST THING EVER. Random Forest's custom validation method: out-of-bag predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOB predictions\n",
    "About a third of observations don't show up in a bootstrap sample. \n",
    "\n",
    "Because an individual tree in the forest is made from a bootstrap sample, it means that about a third of the data was not used to build that tree. We can track which observations were used to build which trees.\n",
    "\n",
    "#### Here is the magic. \n",
    "\n",
    "After the forest is built, we take each observation in the dataset and identify which trees used the observation and which trees did not use the observation (based on the bootstrap sample). We use the trees the observation was not used to build to predict the true value of the observation. About a third of the trees in the forest will not use any specific observation from the dataset. \n",
    "\n",
    "OOB predictions are similar to following awesome, but computationally expensive method: \n",
    "1. Train a model with n_estimators trees, but exclude one observation from the dataset.\n",
    "2. Use the trained model to predict the excluded observation. Record the prediction.\n",
    "3. Repeat this process for every single observation in the dataset.\n",
    "4. Collect all your final predictions. These will be similar to your oob prediction errors. \n",
    "\n",
    "The leave-one-out method will take n_estimators\\*time_to_train_one_model\\*n_observations to run. \n",
    "\n",
    "The oob method will take n_estimators\\*time_to_train_one_model\\*3 to run (the \\*3 is because if you want to get an accuracy estimate of a 100 tree forest, you will need to train 300 trees. Why? Because with 300 trees each observation will have about 100 trees it was not used to build that can be used for the oob_predictions).\n",
    "\n",
    "This means the oob method is n_observations/3 times faster to train then the leave-one-out method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full example. Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Your first goal always should be getting a generalized prediction as fast as possible.\n",
    "* This doesn't mean to skip exploratory data analysis (EDA). It just means to not get caught up on it. Initially do only what is needed to get a generalized prediction.\n",
    "* Getting a prediction first lets you set a benchmark for yourself. As you make improvements to the model, you should be able to see your desired error metric improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the goal above, I will import just what I need. \n",
    "# The model to use (I already imported it above, but will do it again here so each example is self-contained)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# The error metric. In this case, we will use c-stat (aka ROC/AUC)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# An efficient data structure. \n",
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "X = pd.read_csv(\"../data/train.csv\")\n",
    "y = X.pop(\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know that there are categorical variables in the dataset, but I will skip them for the moment. I will impute age though, because it will be fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Age with mean\n",
    "X[\"Age\"].fillna(X.Age.mean(), inplace=True)\n",
    "\n",
    "# Confirm the code is correct\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the numeric variables by selecting only the variables that are not \"object\" datatypes.\n",
    "numeric_variables = list(X.dtypes[X.dtypes != \"object\"].index)\n",
    "X[numeric_variables].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice PassengerId looks like a worthless variable. I leave it in for two reasons. First, I don't want to go through the effort of dropping it (although that would be very easy). Second, I am interested in seeing if it is useful for prediction. It might be useful if the PassengerId was assigned in some non-random way. For example, perhaps PassengerId was assigned based on when the ticket was purchased in which case there might be something predictive about people who purchased their tickets early or late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build our first model. I always have oob_score=True. It is a good idea to increase n_estimators to a number higher than \n",
    "# the default. In this case the oob_predictions will be based on a forest of 33 trees. I set random_state=42 so that you all can\n",
    "# replicate the model exactly.\n",
    "model = RandomForestRegressor(n_estimators=100, oob_score=True, random_state=42)\n",
    "\n",
    "# I only use numeric_variables because I have yet to dummy out the categorical variables\n",
    "model.fit(X[numeric_variables], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regression, the oob_score_ attribute gives the R^2 based on the oob predictions. We want to use c-stat, but I mention this \n",
    "# for awareness. By the way, attributes in sklearn that have a trailing underscore are only available after the model has been fit.\n",
    "model.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oob = model.oob_prediction_\n",
    "print(\"c-stat: \", roc_auc_score(y, y_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a benchmark. This isn't very good for this dataset; however, it provides us a benchmark for improvement. Before changing parameters for the Random Forest, let's whip this dataset into shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a simple function to show descriptive stats on the categorical variables\n",
    "def describe_categorical(X):\n",
    "    \"\"\"\n",
    "    Just like .describe(), but returns the results for\n",
    "    categorical variables only.\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X[X.columns[X.dtypes == \"object\"]].describe().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_categorical(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the variables I don't feel like dealing with for this tutorial\n",
    "X.drop([\"Name\", \"Ticket\", \"PassengerId\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Cabin variable to be only the first letter or None\n",
    "def clean_cabin(x):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return \"None\"\n",
    "\n",
    "X[\"Cabin\"] = X.Cabin.apply(clean_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['Sex', 'Cabin', 'Embarked']\n",
    "\n",
    "for variable in categorical_variables:\n",
    "    # Fill missing data with the word \"Missing\"\n",
    "    X[variable].fillna(\"Missing\", inplace=True)\n",
    "    # Create array of dummies\n",
    "    dummies = pd.get_dummies(X[variable], prefix=variable)\n",
    "    # Update X to include dummies and drop the main variable\n",
    "    X = pd.concat([X, dummies], axis=1)\n",
    "    X.drop([variable], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at all the columns in the dataset\n",
    "def printall(X, max_rows=10):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X.to_html(max_rows=max_rows)))\n",
    "    \n",
    "printall(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(100, oob_score=True, n_jobs=-1, random_state=42)\n",
    "model.fit(X, y)\n",
    "print (\"C-stat: \", roc_auc_score(y, model.oob_prediction_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty good model. Now, before we try some different parameters for the model, let's use the Random Forest to help us with some EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable importance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple version that shows all of the variables\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feature_importances.sort_values(inplace=True)\n",
    "feature_importances.plot(kind=\"barh\", figsize=(7,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex version that shows the summary view\n",
    "\n",
    "def graph_feature_importances(model, feature_names, autoscale=True, headroom=0.05, width=10, summarized_columns=None):\n",
    "    \"\"\"\n",
    "    By Mike Bernico\n",
    "    \n",
    "    Graphs the feature importances of a random decision forest using a horizontal bar chart. \n",
    "    Probably works but untested on other sklearn.ensembles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ensemble = Name of the ensemble whose features you would like graphed.\n",
    "    feature_names = A list of the names of those featurs, displayed on the Y axis.\n",
    "    autoscale = True (Automatically adjust the X axis size to the largest feature +.headroom) / False = scale from 0 to 1\n",
    "    headroom = used with autoscale, .05 default\n",
    "    width=figure width in inches\n",
    "    summarized_columns = a list of column prefixes to summarize on, for dummy variables (e.g. [\"day_\"] would summarize all day_ vars\n",
    "    \"\"\"\n",
    "    \n",
    "    if autoscale:\n",
    "        x_scale = model.feature_importances_.max()+ headroom\n",
    "    else:\n",
    "        x_scale = 1\n",
    "    \n",
    "    feature_dict=dict(zip(feature_names, model.feature_importances_))\n",
    "    \n",
    "    if summarized_columns: \n",
    "        #some dummy columns need to be summarized\n",
    "        for col_name in summarized_columns: \n",
    "            #sum all the features that contain col_name, store in temp sum_value\n",
    "            sum_value = sum(x for i, x in feature_dict.items() if col_name in i )  \n",
    "            \n",
    "            #now remove all keys that are part of col_name\n",
    "            keys_to_remove = [i for i in feature_dict.keys() if col_name in i ]\n",
    "            for i in keys_to_remove:\n",
    "                feature_dict.pop(i)\n",
    "            #lastly, read the summarized field\n",
    "            feature_dict[col_name] = sum_value\n",
    "        \n",
    "    results = pd.Series(feature_dict)\n",
    "    results.sort_values(inplace=True)\n",
    "    results.plot(kind=\"barh\", figsize=(width,len(results)/4), xlim=(0,x_scale))\n",
    "    \n",
    "graph_feature_importances(model, X.columns, summarized_columns=categorical_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to test\n",
    "\n",
    " * ###Parameters that will make your model better\n",
    "  * <b>n_estimators</b>: The number of trees in the forest. Choose as high of a number as your computer can handle.\n",
    "  * <b>max_features</b>: The number of features to consider when looking for the best split. Try [\"auto\", \"None\", \"sqrt\", \"log2\", 0.9, and 0.2]\n",
    "  * <b>min_samples_leaf</b>: The minimum number of samples in newly created leaves.Try [1, 2, 3]. If 3 is the best, try higher numbers such as 1 through 10.\n",
    " * ###Parameters that will make it easier to train your model\n",
    "  * <b>n_jobs</b>: Determines if multiple processors should be used to train and test the model. Always set this to -1 and %%timeit vs. if it is set to 1. It should be much faster (especially when many trees are trained)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "model = RandomForestRegressor(1000, oob_score=True, n_jobs=1, random_state=42)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "model = RandomForestRegressor(1000, oob_score=True, n_jobs=-1, random_state=42)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "n_estimator_options = [30, 50, 100, 200, 500, 1000, 2000]\n",
    "\n",
    "for trees in n_estimator_options:\n",
    "    model = RandomForestRegressor(trees, oob_score=True, n_jobs=-1, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    print (trees, \"trees\")\n",
    "    roc = roc_auc_score(y, model.oob_prediction_)\n",
    "    print (\"C-stat: \", roc)\n",
    "    results.append(roc)\n",
    "    print (\"\")\n",
    "    \n",
    "pd.Series(results, n_estimator_options).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "max_features_options = [\"auto\", None, \"sqrt\", \"log2\", 0.9, 0.2]\n",
    "\n",
    "for max_features in max_features_options:\n",
    "    model = RandomForestRegressor(n_estimators=1000, oob_score=True, n_jobs=-1, random_state=42, max_features=max_features)\n",
    "    model.fit(X, y)\n",
    "    print (max_features, \"option\")\n",
    "    roc = roc_auc_score(y, model.oob_prediction_)\n",
    "    print (\"C-stat: \", roc)\n",
    "    results.append(roc)\n",
    "    print (\"\")\n",
    "    \n",
    "pd.Series(results, max_features_options).plot(kind=\"barh\", xlim=(.85,.88));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "min_samples_leaf_options = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "for min_samples in min_samples_leaf_options:\n",
    "    model = RandomForestRegressor(n_estimators=1000, \n",
    "                                  oob_score=True, \n",
    "                                  n_jobs=-1, \n",
    "                                  random_state=42, \n",
    "                                  max_features=\"auto\", \n",
    "                                  min_samples_leaf=min_samples)\n",
    "    model.fit(X, y)\n",
    "    print (min_samples, \"min samples\")\n",
    "    roc = roc_auc_score(y, model.oob_prediction_)\n",
    "    print (\"C-stat: \", roc)\n",
    "    results.append(roc)\n",
    "    print (\"\")\n",
    "    \n",
    "pd.Series(results, min_samples_leaf_options).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=1000, \n",
    "                              oob_score=True, \n",
    "                              n_jobs=-1, \n",
    "                              random_state=42, \n",
    "                              max_features=\"auto\", \n",
    "                              min_samples_leaf=5)\n",
    "model.fit(X, y)\n",
    "roc = roc_auc_score(y, model.oob_prediction_)\n",
    "print (\"C-stat: \", roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
