{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trials of Flat and Hierarchical Clusterings with Titanic Data\n",
    "[Demo of DBSCAN clustering algorithm — scikit-learn 0.19.0 documentation](http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Generate sample data\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
    "                            random_state=0)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# #############################################################################\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels))\n",
    "\n",
    "# #############################################################################\n",
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn.cluster.DBSCAN — scikit-learn 0.15-git documentation](http://scikit-learn.org/0.15/modules/generated/sklearn.cluster.DBSCAN.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "for eps in range(1,30,1):\n",
    "    for minPts in range(1,20):\n",
    "        dbscan = DBSCAN(eps=eps * 0.1,min_samples=minPts).fit(X)\n",
    "        y_dbscan = dbscan.labels_\n",
    "        \n",
    "        \"\"\" 結果を表示 \"\"\"\n",
    "        labels = dbscan.labels_\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] != -1:\n",
    "                print(labels[i], X[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# タイタニックデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "df0 = pd.read_excel('titanic.xls')\n",
    "#print(df.head())\n",
    "df = df0.drop(['body','name'], 1)\n",
    "df.convert_objects(convert_numeric=True)\n",
    "df.fillna(0, inplace=True)\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 名義尺度を数値に置き換える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_non_numerical_data(df):\n",
    "    columns = df.columns.values\n",
    "\n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            column_contents = df[column].values.tolist()\n",
    "            unique_elements = set(column_contents)\n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "\n",
    "            df[column] = list(map(convert_to_int, df[column]))\n",
    "\n",
    "    return df\n",
    "\n",
    "df = handle_non_numerical_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['survived'], 1).astype(float))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN\n",
    "[CSCE 420 Communication Project - DBSCAN - YouTube](https://www.youtube.com/watch?v=5E097ZLE9Sg&feature=youtu.be)  \n",
    "[Brian Kent: Density Based Clustering in Python - YouTube](https://www.youtube.com/watch?v=5cOhL4B5waU&feature=youtu.be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import csv\n",
    "#import codecs\n",
    "writer = pd.ExcelWriter('DBSCAN.xlsx')\n",
    "trial_no = 0\n",
    "with open('DBSCAN_summary.csv', 'w', newline='') as csv_fd:\n",
    "    csv_writer = csv.writer(csv_fd)\n",
    "    csv_writer.writerow(['eps', 'minPts', 'label count', 'unclustered', 'cluster 1', 'cluster 2', '...'])\n",
    "    ''' 1. 密度を隣接ノードまでの距離(eps)で表現する '''\n",
    "    #for eps in range(100, 3000, 100):        # 群番号1に最大数の群が割り当てられるようだ。\n",
    "    #for eps in [10, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 100, 1000]:\n",
    "    for eps in range(1, 100):\n",
    "\n",
    "        ''' 2. minPts個以下しか集まらない群は、ノイズとして数えない '''\n",
    "        #for minPts in range(10, 200, 10):    # minPts個以下しか集まらない群は、ノイズとして数えない。\n",
    "        for minPts in [10, 100, 10]:        # 群番号は-1で表示される。\n",
    "\n",
    "            dbscan = DBSCAN(eps=eps,min_samples=minPts).fit(X)\n",
    "            y_dbscan = dbscan.labels_\n",
    "\n",
    "            \"\"\" 結果を表示 \"\"\"\n",
    "            labels = dbscan.labels_\n",
    "            #for i in range(len(labels)):\n",
    "            #    if labels[i] != -1:\n",
    "            #        print(labels[i], X[i])\n",
    "            df1 = df0     # df1: 書き出し用のデータフレーム\n",
    "            if 2< len(set(labels)) < 20:        # 群数が3以上20未満の場合に書き出すようにしている。その場合は下に出力する。\n",
    "                                                            # 群数が2の場合は、未分類と分類0の2群なので書き出さない\n",
    "                df1['minPts={}'.format(minPts)] = labels\n",
    "                cluster_count_dict = dict()\n",
    "                for label in labels:\n",
    "                    cluster_count_dict[label] = cluster_count_dict.get(label, 0) + 1\n",
    "                trial_no += 1\n",
    "                #print(cluster_count_dict)\n",
    "                print('{}: eps = {:.1f}, minPts = {}, 異なり数 = {}'.format(trial_no, eps, minPts, len(set(labels))))\n",
    "                count_list = [x[1] for x in sorted(cluster_count_dict.items(), key = lambda x: x[0])]\n",
    "                csv_writer.writerow([eps, minPts, len(set(labels))] +count_list)\n",
    "                print(repr([eps, minPts, len(set(labels))] +count_list))\n",
    "                \n",
    "                #print('  {}'.format(sorted(cluster_count_dict.items(), key = lambda x: x[0])))\n",
    "                #cluster_count_list = sorted(cluster_count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "                #print(cluster_count_list)\n",
    "                df1.to_excel(writer,'eps={}'.format(eps))\n",
    "               # cluster_count_dictをリストでシートに書き出す\n",
    "        #df1.to_excel(writer,'eps={}'.format(eps))\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn.cluster.AgglomerativeClustering — scikit-learn 0.19.0 documentation](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html)\n",
    "\n",
    "affinity : string or callable, default: “euclidean”\n",
    "Metric used to compute the linkage. Can be “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or ‘precomputed’. If linkage is “ward”, only “euclidean” is accepted.\n",
    "\n",
    "linkage : {“ward”, “complete”, “average”}, optional, default: “ward”\n",
    "Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion.\n",
    "ward minimizes the variance of the clusters being merged.\n",
    "average uses the average of the distances of each observation of the two sets.\n",
    "complete or maximum linkage uses the maximum distances between all observations of the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import csv\n",
    "import collections\n",
    "\n",
    "writer = pd.ExcelWriter('AgglomerativeClustering.xlsx')\n",
    "trial_no = 0\n",
    "    \n",
    "#from sklearn import cluster\n",
    "# implementing agglomerative (bottom up) hierarchical clustering\n",
    "# we're going to specify that we want 4 and 2 clusters, respectively\n",
    "print(\"Dataset X\")\n",
    "\n",
    "affinity_list = ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
    "linkage_list = ['ward', 'complete', 'average']\n",
    "for affinity in affinity_list:\n",
    "    for linkage in linkage_list:\n",
    "        if affinity == 'euclidean':\n",
    "            if linkage != 'ward':\n",
    "                continue\n",
    "        if linkage == 'ward':\n",
    "            if affinity != 'euclidean':\n",
    "                continue\n",
    "        print('affinity = {}, linkage = {}'.format(affinity, linkage))\n",
    "        with open('AgglomerativeClustering_summary_{}_{}.csv'.format(affinity, linkage), 'w', newline='') as csv_fd:\n",
    "            csv_writer = csv.writer(csv_fd)\n",
    "            csv_writer.writerow(['n_clusters', 'cluster 1', 'cluster 2', '...'])\n",
    "            for n in range(20, 1, -1):\n",
    "                df1 = df0     # df1: 書き出し用のデータフレーム\n",
    "                labels = AgglomerativeClustering(n_clusters=n, affinity=affinity, \n",
    "                                                              linkage=linkage).fit_predict(X)\n",
    "                df1['n={}'.format(n)] = labels\n",
    "                #print(df1['n={}'.format(n)])\n",
    "                #df1.to_excel(writer,'{}_{}'.format(affinity, linkage))   # シート名\n",
    "                print(len(labels))\n",
    "                print('n_clusters: {}'.format(n))\n",
    "                print(*[\"  Cluster \"+str(i)+\": \"+ str(sum(labels==i)) for i in range(n)], sep='\\n')\n",
    "\n",
    "                # サマリー情報\n",
    "                trial_no += 1\n",
    "                count_list  = []\n",
    "                for i in range(n):\n",
    "                    count_list.append(sum(labels==i))\n",
    "                csv_writer.writerow([n] +count_list)\n",
    "                \n",
    "            df1.to_excel(writer,'{}_{}'.format(affinity, linkage))   # シート名\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
